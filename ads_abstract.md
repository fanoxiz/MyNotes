---
title: "Алгоритмы и структуры данных, 2025"
author: "@witzberg"
date: "2025-06-18"
---

## 1.
### Задача о кузнечике (набор максимальной суммы на массиве).

$\blacksquare$ **Содержание:**

Дан массив "баллов" в каждой ячейке, можно переходить на следующую или через одну. Нужно набрать наибольшую сумму.

```py
# База
dp[0] = 0

# Переход
dp[i] = a[i] + max(dp[i - 1], dp[i - 2])

# Ответ
dp[n + 1]
```

$\blacksquare$ **Асимптотика:**  
$O(n)$

## 2.
### Задача о черепашке (набор максимальной суммы на таблице). Восстановление ответа.

$\blacksquare$ **Содержание:**

Задачка как в ЕГЭ по Excel, но проще, потому что без бортиков.

```py
# База
dp[0][0] = a[0][0]
dp[0][i] = dp[0][i - 1] + a[0][i]
dp[i][0] = dp[i - 1][0] + a[i][0]

# Переход
dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) + a[i][j]

# Ответ
dp[n][m]

# Восстановление пути
Для каждой dp[i][j] храним путь (сверху или слева пришли в нее). Затем с конца идем и восстанавливаем.
```

$\blacksquare$ **Асимптотика:**  
$O(nm)$

## 3.
### Задача о наибольшей общей подпоследовательности.

$\blacksquare$ **Содержание:**

Даны строки $s$ и $t$. Надо найти НОП. Пусть $dp[i][j]$ - НОП для строк $s[:i+1]$ и $t[:j+1]$ (срез до $i$ включительно).

```py
# База
dp[0][*] = 0
dp[*][0] = 0

# Переход
Если новый символ не внес ничего нового (это когда s[i] != t[i]), то:

dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])

Иначе, чтобы новый символ дополнил НОП, s[i] и t[i] должны быть равны. Тогда: 

dp[i] = dp[i - 1][j - 1] + 1

# Ответ
dp[n][m]
```

**[ ! ]** Можно не сравнивать последние символы и просто брать максимум из 3 случаев. Это тоже корректно

$\blacksquare$ **Асимптотика:**  
$O(nm)$

## 4.
### Задача о наибольшей возрастающей подпоследовательности: решение за $O(n \log n)$ с помощью бинарного поиска.

$\blacksquare$ **Содержание:**

Дана последовательность, надо найти НВП. Пусть $tails[k]$ - наименьший конечный элемент среди всех НВП длины $k + 1$. Изначально $tails$ пуст. Заметим, что он всегда отсортирован по возрастанию. Итерируемся по $a$:

Если $a[i] \gt tails[-1]$, то самую длинную НВП можно дополнить $a[i]$.  
Иначе, $a[i]$ может уменьшить последний элемент для одной из более коротких НВП. Найдем минимальный $k$, что $tails[k] \ge a[i]$ с помощью бинопоиска.

```py
# Переход
if (a[i] > tails[-1]) {
  tails.push_back(a[i])
}
else {
  tails[BinSearch(lambda x: tails[x] >= a[i])] = a[i]
}

# Ответ
tails.size()
```

$\blacksquare$ **Асимптотика:**  
$O(n \log n)$

## 5.
### Задача о наибольшей возрастающей подпоследовательности: решение за $O(n \log n)$ с помощью дерева отрезков или дерева Фенвика со сжатием координат.

$\blacksquare$ **Содержание:**

Строим ДП не как обычно: $dp[k]$ - длина НВП, кончающейся на элементе со значением $k$ (**Самая важная часть всей задачи!**).

```py
# Переход
dp[a[i]] = 1 + max{по всем val < a[i]} dp[val] # Если таких нет, то max = 0
```

Так как значения могу быть большими, а их количество - маленьким, сжимаем координаты. Пусть после сжатия $a[i] \leftrightarrow a_{cmp}[i]$ ($compressed$). 

Наше $dp$ будет не массивом, а ДО на максимум (**Тоже самая важная часть всей задачи!**). Тогда, для $a[i]$ за $O(\log n)$ получаем максимум на отрезке [MIN_VAL (*глобальный минимум*), $a_{cmp}[i])$. Пытаемся обновить $dp[i]$ новым значением.

```py
# Максимальное значение, строго меньшее a_cmp[i]:
new_len = ДО.query(MIN_VAL, a_cmp[i] - 1)

# Обновление ДП:
ДО[a_cmp[i]] = max(ДО[a_cmp[i]], max(new_len))

# Ответ
ДО.query(MIN_VAL, MAX_VAL) # т.е. max{по всем 0 <= i < n} dp[i]
```

$\blacksquare$ **Асимптотика:**  
$O(n \log n)$

## 6.
### Задача о рюкзаке: решения с динамикой по весу или по стоимости, что лучше выбрать.

$\blacksquare$ **Содержание:**

Есть $n$ предметов: $item_i = (w_i, c_i)$ - weight и cost. Нужно набрать предметов на максимальную стоимость, чтобы сумма их весов не превышала емкость рюкзака ($W$). Веса и стоимости неотрицательны. Есть два варианта построения ДП:

- По весу:  
$dp[...][вес]$ хранит максимальную стоимость.  
- По стоимости:  
$dp[...][стоимость]$ хранит минимальный вес.

Если емкость мала, а стоимость велика, то по весу.  
Если стоимость мала, а емкость велика, то по стоимости.

Решение с ДП по весу: пусть $dp[i][a]$ - наибольшая стоимость из первых i элементов с суммой веса **ровно** a.

```py
# База
dp[0][*] = -\infty
dp[0][0] = 0

# Переход
Если не берем i + 1 предмет:

dp[i + 1][a] = dp[i][a]

Если берем, то нужно учитывать наличие места под новый i + 1 предмет:

dp[i + 1][a] = dp[i][a - w_{i + 1}] + c_i

# Ответ
max{по всем 0 <= a <= W} dp[n][a]
```

$\blacksquare$ **Асимптотика:**  
$O(n \cdot W)$, где $W$ - емкость рюкзака (или сумма всех стоимостей, если ДП по стоимости).  
Эта задача NP-трудная, то есть не решается за полиномиальное время.

## 7.
### Бинарное возведение чисел и матриц в степень, асимптотика.

$\blacksquare$ **Содержание:**

$$
A^n =
\begin{cases}
1, & \text{если } n = 0 \\
(A^{\frac{n}{2}})^2, & \text{если } n \text{ четно} \\
A \cdot A^{n - 1}, & \text{если } n \text{ нечетно}
\end{cases}
$$

Псевдокод:

```py
Binpow(Matrix a, n) {
  if (n == 0) {
    return 1
  }
  if (n % 2 == 1) {
    return Binpow(a, n - 1) * a
  }
  else {
    Matrix b = Binpow(a, n / 2)
    return b * b
  }
}
```

$\blacksquare$ **Асимптотика:**  
$O(k^3 \cdot \log n)$, где $k$ - размер матрицы (т.к. умножение матриц $k \times k$ занимает $O(k^3)$).

## 8.
### Подсчёт n-го числа Фибоначчи (по модулю m) за $O(\log n)$.

$\blacksquare$ **Содержание:**

Нужно найти $n$-ое число Фибоначчи по модулю $m$. Формула не подходит, т.к. получаются иррациональные числа, так еще и неоптимально. Можно использовать бинарное возведение матриц в степень.

$$
\begin{pmatrix} F_{n  } \\ F_{n - 1} \end{pmatrix}
=
\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}
\cdot
\begin{pmatrix} F_{n - 1} \\ F_{n - 2} \end{pmatrix}
=
\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}^2
\cdot
\begin{pmatrix} F_{n - 2} \\ F_{n - 3} \end{pmatrix} = \dots
=
\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}^{n - 1}
\cdot
\begin{pmatrix} F_1 \\ F_0 \end{pmatrix}
$$

Теперь осталось возвести в $n - 1$ степень (бинарно, за $O(\log n)$) матрицу $\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}$

$\blacksquare$ **Асимптотика:**  
$O(\log n)$

## 9.
### Подсчёт n-го члена рекурренты $a_n = \lambda a_{n-1} + \mu a_{n-2} + 1$ (по модулю m) за $O(\log n)$ для произвольных констант $\lambda$ и $\mu$.

$\blacksquare$ **Содержание:**

Аналогично Фибоначчи, нужно лишь возвести матрицу перехода в нужную степень.

$$
\begin{pmatrix} a_n \\ a_{n - 1} \\ 1 \end{pmatrix}
=
\begin{pmatrix} \lambda & \mu & 1 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}
\cdot
\begin{pmatrix} a_{n - 1} \\ a_{n - 2} \\ 1 \end{pmatrix}
$$

$\blacksquare$ **Асимптотика:**  
$O(\log n)$,  
т.к. $3^3$ - константа.

## 10.
### Количество путей длины ровно k между всеми парами вершин за $O(n^3 \cdot \log k)$.

$\blacksquare$ **Содержание:**

Есть невзвешенный ориентированный граф (его матрица смежности $M$, т.е $M_{u, v} = 1 \Leftrightarrow$ есть ребро $(u, v)$). Нужно найти количество путей из $x$ в $y$ длины ровно $k$. Далее индукция. Посчитаем количество способов попасть в $v$ по 2 ребрем:

$\sum_{p = 1}^{n} (\exists\ ли\ u \to p) \times (\exists\ ли\ p \to v)$  

Это в точности определение умножения матриц:
$(M \times M)_{u, v} = \sum_{p=1}^{n} M_{u, p} \cdot M_{p, v}$.

По индукции $(M^k)_{u, v}$ дает количество различных путей длины ровно $k$ из вершины $u$ в вершину $v$.

$\blacksquare$ **Асимптотика:**  
$O(n^3 \log k)$, где $n$ - размер матрицы M.

## 11.
### Количество путей длины не более k между всеми парами вершин за $O(n^3 \cdot \log k)$.

$\blacksquare$ **Содержание:**

По предыдущему билету, ответом будет $(u, v)$ элемент, но не $M^k$, а $\sum_{i}^{k} M^i$. Осталось научиться быстро находить эту сумму.

$f(M, k) = (M^k, \sum_{i = 0}^{k} M^i)$

$$
f(M, k) =
\begin{cases}
\text{Если $k = 0$:} \\
\text{Возвращаем $(E, E)$} \\
\\
\text{Если $k$ нечетно:} \\
\text{Считаем $f(M, k - 1)$, первый элемент результата $(M^{k - 1})$} \\
\text{домножаем на $M$, прибавляем ко второму элементу и возвращаем} \\
\\
\text{Если $k$ четно:} \\ 
\text{Считаем $f(M, \frac{k}{2}))$, второй элемент $(\sum_{i = 0}^{\frac{k}{2}} M^i)$} \\
\text{домножаем на первый без единичной матрицы $(M^{\frac{k}{2}} - E)$, чтобы получилось} \\
\text{ровно $\sum_{i = 0}^{k} M^i$). Возвращем (Первый$^2$, $\sum_{i = 0}^{k} M^i$)}
\end{cases}
$$

$\blacksquare$ **Асимптотика:**  
$O(n^3 \log k)$, где $n$ - размер матрицы M.

## 12.
### Булевское умножение матриц. Проверка наличия пути длины ровно k между всеми парами вершин за $O(\frac{n^3}{w} \cdot \log k)$.

$\blacksquare$ **Содержание:**

Теперь нас не волнует количество, нужно узнать есть ли хотя бы один. Определим бинарное умножение матриц (да / нет, есть путь / нет пути). То есть по сути заменяем сумму на дизъюнкцию, а произведение - на конъюнкцию.

$$
A \otimes B = C, \
C_{i, j} = \bigvee_{z = 0}^{k} (A_{i, z} \land B_{z, j})
$$

$(M^{\otimes k})_{u, v}$ будет означать, есть ли путь из $u$ в $v$.

$\blacksquare$ **Асимптотика:**  
$O(\frac{n^3}{w} \cdot \log k)$  
Т.к. вместо попарного произведения, можно разделить строку на куски длины $w$ (машинное слово), затем применить побитовую конъюнкцию к каждому куску (работает за $O(1)$). Если хотя бы в одном куске получается 1, то вся дизъюнкция тоже верна.

## 13.
### Кодирование подмножеств $\{0, 1, ..., n − 1\}$ с помощью масок. Процедура извлечения бита (bit).

$\blacksquare$ **Содержание:**

Есть небольшое множество (не более 32 или 64 элементов). Нужно работать с его подмножествами. Храним маску - число, где каждый бит в двоичной системе означает наличие элемента в данном подмножестве. Чтобы проверить, входит ли x в множество, нужно извлечь бит, отвечающий за данный элемент.

```py
bit(mask, pos) {
  # Срезаем все биты до нужного, возвращаем его
  return (mask >> pos) & 1
}
```

$\blacksquare$ **Асимптотика:**  
$O(1) \leq O(\log 32)$  
Работает это за логарифм длины машинного слова, т.е. константа.

## 14.
### Операции над множествами (масками): объединение, пересечение, разность. Реализация в программе. Проверка, что одна маска является подмножеством другой.

$\blacksquare$ **Содержание:**

Операции над множествами выражаются через битовые операции над их масками.

- Обьединение:

$A \cup B = mask_A\ |\ mask_B$

- Пересечение:

$A \cap B = mask_A\ \&\ mask_B$

- Разность:

$A \setminus B = mask_A\ \&\ \neg mask_B$

- Проверка на подмножество:

$A \subset B \Leftrightarrow A \setminus B = \varnothing$

$\blacksquare$ **Асимптотика:**  
$O(1)$

## 15.
### Задача о назначениях: решение за $O(2^n \cdot n^2)$.

$\blacksquare$ **Содержание:**

Есть $n$ работников и столько же заданий. Нужно каждому дать по одному заданию, чтобы минимизировать суммарные затраты времени или денег на всех рабочих. $a_{i, j}$ - стоимость выполнения $i$ задания $j$ работником. 

В моменте надо знать потраченную сумму и какие задачи уже распределены. Пусть $dp[i][mask]$ - минимальная стоимость распределить первых $i$ работников, чтобы они выполнили задачи $mask$.

```py
# Переход
dp[i][mask] = min{по всем задачам b из маски} a_{i, b} + dp[i - 1][mask \ b] # mask \ b == mask xor 2^b
```

То есть перебираем все состояния $dp$ ($2^n \cdot n$ штук), и для каждого выбираем $\min$ из n. 

$\blacksquare$ **Асимптотика:**  
$O(2^n \cdot n^2)$  
Эта задача не NP-трудная, в конце семестра будет ее полиномиальное решение.

## 16.
### Задача о максимальной клике: решение за $O(2^n)$.

$\blacksquare$ **Содержание:**

```py
См. следующий билет
```

$\blacksquare$ **Асимптотика:**  
$O(2^n)$  
Эта задача не решается за полиномиальное время.

## 17.
### Задача о максимальной клике: решение за $O(2^{\frac{n}{2}})$.

$\blacksquare$ **Содержание:**

Дан граф в виде матрицы смежности. Нужно найти в нем максимальную клику.

**| Клика** - подмножество вершин, в котором любые две связаны.

Введем несколько методов:
```py
# Обозначает, является ли множество вершин mask кликой.
# Будет работать за O(1) благодаря предподсчету.
clique(mask) -> bool {
  # Если mask - клика, то произвольная вершина v соединена со всеми, и mask \ v тоже клика
  return (clique(mask \ v)) and ((mask \ v) подмножество neighbor(v))
}

# Возвращает маску всех соседей v (работает за O(n), хотя Степанов сказал за O(n^2)).
neighbor(v) -> mask {
  перебираем строку, относящуюся к v
}

Теперь надо как-то выбрать произвольную v. Удобно брать старший бит маски:

# Находит позицию старшего бита. Работает за O(k) или даже за O(log k), хотя Степанов сказал за O(2^k).
oldest(mask) -> int {
  return max степень двойки + 1
  # Например для 101_2 = 5_10 ответ 3 = 2 + 1
}

# Размер максимальной клики, вложенной в mask.
subclique(mask) -> int {
  if (clique(mask)) return |mask| # Сколько бит включено
  # Пусть v - старшая вершина (ее бит старший).
  # Если она не входит в клику, которую мы ищем, то
  # запускаем рекурсивно без нее. Если же она входит, то
  # запускаем только от нее и ее соседей. Из двух берем max
  return max(subclique(mask v), subclique(mask & neighbor(v)))
}
```

Теперь вернемся к решению исходной задачи. Поделим граф на 2 примерно равных куска (по количеству вершин). Клика, с точки зрения этого разбиения, делится на 2 клики в каждом из кусков, причем каждая вершина из каждой части соединена со всеми на противоположной.

Перебираем все возможные подмножества левой половины, проверяем, являются ли они кликами. Если маска клика, то ищем для нее $corr[mask]$ - множество вершин в правой доле, которые соединены со всеми вершинами из маски (для каждого бита в маске ищем $neighbor()$ от этой вершины, побитовой коньюнкцией оставляем только тех соседей, что в правой доле. И находим коньюнкцию всех масок соседей для всех битов в маске клики, т.е. маску тех соседей, что соединены со всеми вершинами из клики). Сохраняем все пары $(mask, corr[mask])$. Для каждой надо выбрать подклику в другой половине графа, которая плотно соединена с первой.

Далее проходимся по списку и обновляем $\max$ значением размер клики в правой половине + максимальная подклика в маске соседей ($corr[mask]$).

$subclique(corr[mask])$ - искомое дополнение клики из правой половины.

```py
# Ответ
max{по всем mask из левой части, что clique(mask) == True} |mask| + subclique(corr[mask])
```

$\blacksquare$ **Асимптотика:**  
$O(2^{\frac{n}{2}})$

## 18.
### Число замощений таблицы $n \times m$ доминошками: динамика по прямому профилю.

$\blacksquare$ **Содержание:**

Есть табличка $n \times m$, но некоторые клетки выколоты. Нужно найти количество способов, которыми можно покрыть всю табличку доминошками $1 \times 2$. Пересекать, выходить за края или устанавливать на выколотые клетки доминошки нельзя. Пусть $dp[j][mask]$ - количество способов заполнить первые $j$ столбцов, что на $j + 1$ столбце некоторые доминошки будут торчать, образовывая маску.

```py
# База
dp[0][0] = 1 # Торчать не могут
dp[0][*] = 0

# Переход
Перебирая все маски old_mask с прошлого слоя, если mask не пересекается с old_mask и все пустые блоки четной длины:
dp[j][mask] += dp[j - 1][old_mask]
```

$\blacksquare$ **Асимптотика:**  
$O(4^n \cdot m)$  
C возможностю улучшения до $O(3^n \cdot m)$, если перебирать не все $old\_mask$, а сразу только те, что $\subset\ \neg\ mask$:

```py
for (B = A; B > 0; B = (B - 1) & A) { ... }
```

## 19.
### Число замощений таблицы $n \times m$ доминошками: динамика по изломанному профилю.

[Картинка для наглядности](https://youtu.be/ZtxXlW5xLeA?si=1enibSW2DAZt4-ko&t=4590)

$\blacksquare$ **Содержание:**

Профиль - множество торчащих доминошек. До этого профиль был прямой, но можно оптимизировать решение, если рассматривать изломанный. Т.е. столбец со ступенькой. Верхняя часть заполнена полностью, в нижней могут быть торчки. Но также торчки могут быть и в верхней части, но торчать они будут в уже следующий, $j + 1$ столбец. Храним все торчки маской.

$dp[j][i][mask]$ - количество способов покрыть область, для которой точка $(i, j)$ является точкой излома (ступенькой), доминошки торчат по маске.

Теперь можно добавлять не по целому столбцу, а по одной клетке, постепенно опуская ступеньку, в конце переходя на следующий столбец.
Используем ДП вперед.

```py
# База
dp[0][0][0] = 1

# Переход
if bit(mask, i) {
  # Если в клетке (i, j) торчит доминошка
  dp[j][i + 1][mask \ i] += dp[j][i - 1][mask | (1 << i)]
}
if not bit(mask, i) {
  # Клетка не покрыта. Можно положить доминошку
  # вниз (и заодно занять (j + 1, i)) или
  # вправо (и занять (j, i + 1)). Второе можно сделать
  # всегда, а первое - если в (j + 1, i) не торчит.
  if bit(mask, i) == bit(mask, i + 1) == False {
    dp[j][i + 1][mask | (1 << i)]

    < Что то должно быть, но лекция кончилась >
  }
}
```

$\blacksquare$ **Асимптотика:**  
$O(2^n \cdot nm)$

## 20.
### Поиск в глубину: алгоритм DFS на ориентированном графе. Лемма о белых путях.

$\blacksquare$ **Содержание:**

**| Граф** $G = (V, E)$ - множества vertices и edges, они конечны ($|V| = n$, $|E| = m$).

Рассматриваем ориентированный граф. Храним его в виде списка инцидентностей. $g[u]$ - массив из вершин v, для который существует ребро $(u, v)$. Нужно обойти его поиском в глубину. Дополнительно храним:

```py
parents[]   # Откуда пришли в каждую вершину
tin[]       # Время входа в вершину
tout[]      # Время выхода из вершины
color[]     # Цвет вершин, изначально все белые
timer = 0   # Глобальное время

# Значение цвета вершины:
Белый - не встречали
Серый - в обработке
Черный - закончили

DFS(u) {
  color[u] = GRAY
  tin[u] = timer++
  for (v: g[u]) {
    if (color[v] == GRAY) # Нашли цикл
    if (color[v] == WHITE) {
      DFS(v)
      parent[v] = u
    }
  }
  tout[u] = timer++
  color[u] = BLACK
}
```

$\blacksquare$ **Асимптотика:**  
$O(n + m)$

> &nbsp;  
> *(Лемма о белых путях)* "Все, что достижимо из вершины $v$, за промежуток $[tin[v], tout[v]]$ будет посещено и покрашено в черный"  
> &nbsp;

$\triangle$  
Понятно, что перекрасить можем только достижимые вершины. Серые вершины - стек рекурсии $\implies$ на момент $tout[v]$ новых не появится. Белых вершин не могло остаться, т.к. если мы рассмотрим самую верхнюю из оставшихся белых вершины (предположим такие есть), то родитель стал черным, а он не может таковым стать без захода в ребенка $\square$

## 21.
### Поиск в глубину: множество посещаемых вершин, поиск цикла, достижимого из s, проверка на ацикличность.

$\blacksquare$ **Содержание:**

> &nbsp;  
> "В графе существует цикл, достижимый из $s$  $\Leftrightarrow$  DFS($s$) увидит ребро в серую вершину"  
> &nbsp;

$\triangle$  
$\Leftarrow$ Серая вершина - стек рекурсии $\implies$ вход в нее - цикл.  
$\implies$ Выберем в цикле вершину $v$, в которую войдем первой. У нее минимальный $tin$. По лемме о белых путях, при выходе из $v$ все достижимое из нее (т.е. весь цикл) будет посещено $\implies$ побываем в вершине, замыкающей цикл, т.е. ведущей в $v$, которая будет серой на тот момент $\square$

## 22.
### Топологическая сортировка ориентированного ациклического графа: определение и алгоритм поиска (с доказательством корректности). Число путей в ориентированном ациклическом графе.

$\blacksquare$ **Содержание:**

**| DAG** - ориентированный ациклический граф.

**| Топологическая сортировка** - перестановка вершин, такая что для любых вершин $u, v$: $(u, v)$ существует $\implies$ $u$ левее $v$.

> &nbsp;  
> "Граф DAG $\Leftrightarrow$ топологическая сортировка $\exists$"  
> &nbsp;

$\triangle$  
$\Leftarrow$ очев.  
$\implies$ Предъявим алгоритм:

```py
color[*] = WHITE

for (v: g) {
  if (color[v] == WHITE) {
    DFS(v)
  }
}

# Ответ
tout.sort(reverse=True)
```
Почему это верно?

Т.к. $tout$ убывает, нужно лишь доказать, что не бывает ребер из меньшего $tout$ в больший.  

Предположим есть $(u, v)$, что $tout[u] \lt tout[v]$.

1) Если $tin[u] \lt tin[v]$, то $v$ белая на момент входа в $u$. Тогда по лемме о белых путях, из $v$ мы должны выйти раньше чем из $u$. Противоречие.

2) Если $tin[u] \gt tin[v]$. Тогда после входа в $u$, вершина $v$ еще серая. Из $u$ можно попасть в $v$ $\implies$ цикл. Противоречие.

Число путей:

```py
for (u: topsort) {
  dp[u] = 1
  for (v: parents[u]) {
    dp[u] += dp[v]
  }
  total += dp[u]
}
```

$\blacksquare$ **Асимптотика:**  
$O(n + m)$  
Т.к. сортировать в конце можно за $O(n)$, подсчетом ($timer$ ограничен).

## 23.
### Отношение сильной связности между вершинами. Компоненты сильной связности. Сильно связный граф.

$\blacksquare$ **Содержание:**

**| Сильная связанность** двух вершин в графе -
если есть путь в обе стороны.

**[ ! ]** Это отношение эквивалентности.

**| Компонента сильной связности (КСС)** -
подграф, в котором любые две вершины сильно связаны.

**| Сильно связный граф** - в котором одна КСС.

## 24.
### Алгоритм Косарайю.

$\blacksquare$ **Содержание:**

Алгорит Косарайю выделяет КСС в графе. Начало как в topsort:

```py
color[*] = WHITE

for (v: g) {
  if (color[v] == WHITE) {
    DFS(v)
  }
}

tout.sort(reverse=True)
```

Транспонируем граф: заменяем $(u, v)$ на $(v, u)$. Это не испортит КССы, т.к. для любых двух вершин сохранятся пути в обе стороны, просто свапнутся между собой. Затем последовательно вызываем DFS:

```py
for (v: tout) {
  if (not used[v]) {
    DFS(v)
  }
}
```

Все вершины, что обойдем за каждый обход DFS, образуют отдельную КСС.

Для понимания корректности - т.к. мы начинаем с вершин с наибольшим $tout$, то из них был путь в остальные. То т.к. мы инвертировали все ребра, то теперь самая первая КСС замкнута. Из второй КСС можно попасть только в первую, но она уже будет обработана. И т.д.

Также, пусть алгоритм Косарайю нумерует КСС в порядке обнаружения. $id[v]$ - номер компоненты, содежащей вершину $v$. Если есть ребро $(a, b)$, то $id[a] \le id[b]$.

$\blacksquare$ **Асимптотика:**  
$O(n + m)$ 

## 25.
### Постановка и решение задачи 2SAT (применение алгоритма выделения компонент сильной связности).

$\blacksquare$ **Содержание:**

Есть булевы переменные $x_1, \dots , x_n$. Дана 2-КНФ - конъюнкция дизъюнктов пар переменных (например, $(x_1 \cup x_2) \cap (x_2 \cup \neg x_3) \cap \dots)$.  
Нужно проверить, разрешима ли формула и найти какое нибудь из наборов. Для этого перепишем диъюнкции на импликации:

$(a \cup b) = (\neg a \implies b) = (\neg b \implies a)$

Строим граф на $2n$ вершин, $x_i$ и $\neg x_i$ для каждого $i$, для каждой дизъюнкции вводим 2 ребра, отвечающих за две эквивалентные импликации, описанные выше. Тогда, если $x_i$ истина, то все, что достижимо из нее - тоже истина (по свойству импликации).

> &nbsp;  
> "Формула выполнима $\Leftrightarrow$ для любого $i$ вершины $x_i$ и $\neg x_i$ лежат в разных КСС"  
> &nbsp;

$\triangle$  
$\implies$ очев, иначе противоречие.  
$\Leftarrow$ Запускаем Косарайю, он нумерует каждую КСС. Положим $x_i$ = 1, если $id[x_i] \gt id[\neg x_i]$, 0 наоборот. Предположим такой набор не истинен. Пусть неверна какая то из дизъюнкций, обозначим ее $x \cup y$. Тогда $x$ = 0, $y$ = 0 $\implies$ $id[\neg x] \gt id[x]$, $id[\neg y] \gt id[y]$. По построению есть ребра $(\neg x, y)$ и $(\neg y, x)$.  
Но по Косарайю:  
$(a, b)$ существует $\Leftrightarrow$ $id[a] \le id[b]$. Подставляем, получаем противоречие.

$\blacksquare$ **Асимптотика:**  
$O(n + m)$  
Для 3-КНФ и более эта задача NP-трудная.

## 26.
### Определение эйлерова цикла. Критерий наличия эйлерова цикла/пути в ориентированном/неориентированном графе `(б/д)`.

$\blacksquare$ **Содержание:**

**| Эйлеров путь** - проходит по всем ребрам, причем ровно по 1 разу (в вершинах может бывать сколько угодно раз).

**| Эйлеров цикл** - путь, у которого начало и конец совпадают.

**| indeg / outdeg** - количество входящих / исходящих ребер.

**Критерий существования для ориентированного графа:**

* Пути - у всех вершин кроме двух $indeg == outdeg$, у оставшихся $indeg == outdeg + 1$ (и наоборот соответственно), и граф слабо связен.

* Цикла - у всех вершин $indeg == outdeg$ и граф сильно связен.

**Критерий существования для неориентированного графа:**

* Пути - Две вершины имеют нечетную степень и граф связен.

* Цикла - Все вершины имеют четную степень и граф связен.

## 27.
### Алгоритм поиска эйлерова цикла.

$\blacksquare$ **Содержание:**

Алгоритм для поиска эйлерова пути:

```py
stack S = []

# Принимает вершину и ребро, по которому попали в нее (parent_edge), в начале NULL
Euler(v, pe = NULL) {
  while (существует e = (v, to) && not used[e]) {
    used[e] = True
    Euler(to, e)
  }
  S.push(pe)
}
```
Последнее пройденное ребро, ведущее обратно в начало, будет первым добавлено в стек, затем предпоследнее и т.д. На вершине стека будет первое ребро в цикле.

$\blacksquare$ **Асимптотика:**  
$O(n + m)$

## 28.
### Алгоритм DFS на неориентированном графе. Дерево обхода DFS. Классификация рёбер на древесные и обратные.

[Иллюстрация](https://youtu.be/LJgA7g7zNgg?si=OuOK-6JgPzNBW-Bf&t=3830)

$\blacksquare$ **Содержание:**

**| Дерево** - неориентированный связный ациклический граф.

**| Дерево обхода DFS** - ориентированная версия неориентированного графа, в которой ребра имеют то направление, в котром их обходил DFS.

На неориентированном графе пропадает необходимость различать серый и черный.  
Ребер между поддеревьями не может существовать (иначе DFS бы присоединил их к одному из поддеревьев). Тогда, все ребра делятся на 2 группы:

**| Прямые (Древесные)** - те, что проходятся DFS-ом.

**| Обратные** - те, что ведут из потомка в предка.

## 29.
### Мосты, точки сочленения. Введение функции ret. Критерий того, что ребро является мостом. Критерий того, что вершина является точкой сочленения.

$\blacksquare$ **Содержание:**

**| Мост** - ребро в неориентированном графе, удаление которого увеличивает число КСС.

**| Точка сочленения** - вершина в неориентинованном графе, удаление которой увеличивает число КСС.

Мостами не могут быть обратные ребра, только древесные, и то только те, что в их поддереве нет обратных ребер, ведущих выше удаляемого ребра.

Введем метод $ret(v)$ - самый высокий прыжок (минимальный $tin$) из поддерева вершины $v$, т.е.

```py
ret(v) = min(
  tin[v],
  tin[u] по всем (w, u), где w в поддереве v
)
```

**Критерий моста:**
* $(v, to)$ древесное
* $ret[to] \gt tin[v]$

**Критерий точки сочленения:**  
* Если $v$ корень: у $v$ хотя бы 2 ребенка

* Если $v$ не корень: $\exist$ древесное $(v, to)$, $ret[to] \ge tin[v]$ (т.е. одно из поддеревьев $v$ связано с корнем только через $v$)

## 30.
### Насчёт ret в неориентированном графе, нахождение мостов и точек сочленения.

$\blacksquare$ **Содержание:**

Алгоритм поиска мостов:

```py
DFS(v, p = NULL) {
  used[v] = True
  tin[v] = ret[v] = timer++
  for (to: g[v]) {
    if (to == p) {
      continue # Ребро по которому пришли, его игнорируем
    }
    if (used[to]) {
      ret[v] = min(ret[v], tin[to]) # Нашли обратное ребро
    } else {
      DFS(to, v)
      ret[v] = min(ret[v], ret[to])
      if (ret[to] > tin[v]) { # Именно строго больше, это важно
        {v, to} - мост
      }
    }
  }
}
```

Алгоритм поиска точек сочленения:

```py
DFS(v, p = NULL) {
  used[v] = True
  tin[v] = ret[v] = timer++

  child_count = 0
  for (to: graph[v]) {
    if (to == p) {
      continue
    }
    if (used[to]) {
      ret[v] = min(ret[v], tin[to])
    } else {
      ++child_count
      DFS(to, v)
      ret[v] = min(ret[v], ret[to])
      if (p == NULL && child_count >= 2) { # Если корень
        v - точка сочленения
      }
      else if (ret[to] >= tin[v]) {
        v - точка сочленения
      }
    }
  }
}
```

$\blacksquare$ **Асимптотика:**  
$O(n + m)$

## 31.
### Определение расстояния в невзвешенном/взвешенном графе.

$\blacksquare$ **Содержание:**

**| Взвешенный граф** $G = (V, E, w)$, $w: E \implies \R$ - веса ребер.

**| Минимальное расстояние** от $s$ до $t$ - $dist(s, t)$.

Если пути нет, то $dist = \infty$.  
Если есть цикл отрицательного веса, то $dist = -\infty$

## 32.
### Поиск в ширину: алгоритм BFS с доказательством корректности.

$\blacksquare$ **Содержание:**

Нужно от вершины $s$ найти расстояние до всех остальных вершин. Поиск в ширину (BFS) применим, если веса всех ребер одинаковы, также как и DFS (эквивалентно - все равны единице). Введем вспомогательный метод - раскрытие. Он будет использоваться во многих будущих алгоритмах.

```py
expand(v) {
  for (e: g[v]) {
    dist[e.to] = min(dist[e.to], dist[v] + e.weight)
  }
  struct.push(e.to) # Если надо
}
```

Весь поиск в ширину:

```py
BFS(s) {
  dist[*] = \infty
  dist[s] = 0

  queue Q = []
  Q.push(s)

  while (not Q.empty()) {
    v = Q.pop()
    for (e: g[v]) {
      new_d = d[v] + 1
      if (new_d < dist[e.to]) { # эквивалентно dist[e.to] == \infty
        dist[e.to] = new_d
        Q.push(e.to)
      }
    }
  }
}
```

К моменту рассмотрения последней вершины из очереди с расстоянием $k$:
1) Для всех вершин на расстоянии меньше $k + 1$ уже найден правильный ответ.
2) Все вершины на расстоянии $k + 1$ лежат в очереди.

База индукции верна, переход очев.

$\blacksquare$ **Асимптотика:**  
$O(n + m)$

## 33.
### Алгоритм 0-k-BFS.

$\blacksquare$ **Содержание:**

Более универсальный вариант BFS, применрим, когда веса ребер находятся в промежутке $[0, k]$. Храним $d[v]$ - минимальный из найденных путей от $s$ до $v$.  

```py
BFS(s) {
  d[*] = \infty
  d[s] = 0

  deque DQ = []
  DQ.push(s)

  while (not DQ.empty()) {
    v = DQ.pop_front()
    for (e: g[v]) {
      new_d = d[v] + e.weight
      if (new_d < d[e.to]) {
        d[e.to] = new_d
        if (e.weight == 0) {
          DQ.push_front(e.to) # Нулевой вес - в приоритете
        }
        else {
          DQ.push_back(e.to)
        }
      }
    }
  }
}
```

$\blacksquare$ **Асимптотика:**  
$O(n + m)$

## 34.
### Двусторонний BFS.

$\blacksquare$ **Содержание:**

Теперь надо найти расстояние между двумя конкретными вершинами. Суть решения - запустить BFS из обеих и в моменте, когда множества обработанных вершин пересекутся - ответ найден. 

$\blacksquare$ **Асимптотика:**  
$O(n + m)$

## 35.
### Алгоритм Дейкстры. Условия применимости, доказательство корректности. Реализации за $O(n^2),\ O(m \cdot \log n),\ O(m + n \log n)$.

$\blacksquare$ **Содержание:**

Нужен алгоритм, определяющий расстояние от заданной вершины в неориентированном графе, в котором ребра могут весить любое неотрицательное число.

```py
Dijkstra(s) {
  d[*] = \infty
  d[s] = 0
  expanded[*] = False

  Struct Q = [] # Есть несколько вариантов структуры
  Q.push({s, 0}) # {вершина, расстояние}

  while (not Q.empty()) {
    (v, d[v]) = Q.ExtractMin() # dist
    if (expanded[v]) {
      continue
    }
    expanded[v] = True
    for (e: g[v]) {
      new_d = d[v] + e.weight
      if (new_d < d[e.to]) {          
        d[e.to] = new_d
        Q.push({e.to, d[e.to]})
        # В куче может лежать одна вершина
        # несколько раз, с разными расстояниями.
        # При ее раскрытии будет выбран
        # кратчайший путь, а при извлечении
        # остальных ее копий, будет выполнен
        # continue, т.к. она уже помечена expanded
      }
    }
  }
}
```

Корректность:

$\triangle$  
Когда $v$ достается из кучи, $d[v]$ гарантированно верный. Из этого следует корректность всего алгоритма. Если кратчайший путь $dist(s, v)$ кончается ребром $(w, v)$, то по индукции, $w$ будет раскрыта с кратчайшим расстоянием $dist(s, w)$ $\square$

$\blacksquare$ **Асимптотика:**  
$O(n^2)$ с массивом,  
$O(m \log n)$ с бинарной кучей,  
$O(m + n \log n)$ с фибоначчиевой кучей.

($n$ ExtractMin-ов, $m$ DecreaseKey-ев)

## 36.
### Двусторонний алгоритм Дейкстры.

$\blacksquare$ **Содержание:**

Также как в двустороннем BFS, запускаем с двух вершин Дейкстру. Когда одна из вершин будет раскрыта с двух сторон, останавливаемся 

$$
dist(s, v) = \min_{m \in \bigcup} d_s[m] + d_t[m]
$$

Корректность:

Пусть найдена раскрытая вершина с двух сторон. Тогда есть путь длины $x + y$. Почему нет короче? Пусть есть путь длины $k \lt x + y$. Тогда $k \gt x$, $k \gt y$ (иначе односторонний поиск раскроет одну из двух начальных вершин раньше чем общую). Рассмотрим "настоящий" кратчайший путь, а именно его часть, длина которой $\ge x$. Тогда длина остатка $\lt y$. То есть этот путь должен был быть раскрыт раньше. 

$\blacksquare$ **Асимптотика:**  
$O(m \log n)$

## 37.
### Алгоритм A*: определения функций $f, g, h$. Реализация.

$\blacksquare$ **Содержание:**

Ищет кратчайшее расстояние между двумя заданными вершинами ($s$ и $t$) с учетом специфик каждой задачи. Это дает некоторый выигрыш (зачастую не асимптотический, константный). Введем функцию - эвристику $h(v)$. Она будет оценивать примерное расстояние $dist(v, t)$. <u>ОНА ДОЛЖНА БЫТЬ ДОПУСТИМОЙ</u> (см. определения ниже). По умолчанию можно использовать евклидово расстояние, но зная особенности задачи, стоит подбирать более точные оценки. $g[v]$ - лучшая из найденных на данный момент длин путей от $s$ до $v$. Необязательно лучшая среди всех, скорее ее оценка сверху.

$f(v) = g[v] + h(v)$

Получается, A* это та же Дейкстра, но с использованием эвристики вместо тупого выбора ближайшей вершины.

```py
A_star(s) {
  g[*] = \infty
  g[s] = 0

  Struct Q = []
  Q.push({s, g[s] + h(s)}) # т.е. {расстояние, оценка}

  while (not Q.empty()) {
    (f_v, v) = Q.ExtractMin() # Минимальный g[v] + h(v)
    if (v == goal) {
      return # Нашли путь
    }
    if (f_v > f(v)) { # Старые записи с менее оптимальными путями пропускаем
      continue
    }
    for (e: graph[v]) {
      new_g = g[v] + e.weight
      if (new_g < g[e.to]) {          
        g[e.to] = new_g
        Q.push({e.to, f(e.to)})
      }
    }
  }
  return \infty # Не нашли путь
}
```

$\blacksquare$ **Асимптотика:**  
$O(m \log n)$

## 38.
### Допустимые и монотонные эвристики в алгоритме A*. Примеры монотонных эвристик на разных сетках.

$\blacksquare$ **Содержание:**

**| Допустимая эвристика** 
- $h(v) \le dist(s, v)$

**| Монотонная эвристика** 
- Удовлетоворяет неравенству треугольника, т.е. $\forall e = (u, v) : h(u) \le h(v) + e.weight$   
- $h(t) = 0$ 

Примеры:  
Если можно ходить по диагонали, то **расстояние Чебышева**:

$h(v) = \max(|\Delta x|, |\Delta y|)$

Если можно ходить везде, то **Евклидово расстояние**:

$h(v) = \sqrt{(\Delta x)^2 + (\Delta y)^2}$

## 39.
### Формулировка работоспособности (корректность и время работы) алгоритма A* в случае монотонной, допустимой или произвольной эвристики. Доказательство для монотонного случая.

$\blacksquare$ **Содержание:**

**|Если произвольная** - никаких гарантий работы (время работы может быть экспоненциальным, $g[\ ]$ не гарантируется), но зачастую приближение на ответ нормальное.

**| Если допустимая** - Каждая вершина может раскрываться несколько раз (в худшем случае все вершины в сумме могут раскрыться $O(exp(n))$ раз), все $g[\ ]$ гарантированно находятся корректно.

**| Если монотонная** - каждая вершина раскрывается не более одного раза, все $g[\ ]$ находятся корректно $\implies$ ничем не хуже Дейкстры, во многом лучше.

$\triangle$  
Когда дойдем до искомой вершины $t$, $f(t) = g[t] + h(t) = g[t]$ (т.к. по монотонности $h(t) = 0$). $g[t]$ - оценка сверху. Но по лемме, изымаемые из кучи длины упорядочены по неубыванию $\implies$ если бы путь был короче $g[v]$, он извлекся бы раньше. $g[v]$ - точный ответ $\square$

## 40.
### Алгоритм Форда - Беллмана: поиск кратчайших расстояний от одной вершины до всех. Реализация, асимптотика (в случае отсутствия отрицательных циклов).

$\blacksquare$ **Содержание:**

Ищет в ориентированном графе (иначе смысл теряется, если есть хотя бы одно отрицательное ребро - это уже цикл) расстояние от одной вершины до всех остальных, ребра могут иметь отрицательные веса. Будем использовать ДП: $dp[k][v]$ - минимальная стоимость пути до $v$ с использованием не более $k$ ребер. Выдает верный ответ для некоторых вершин только в случае, если отрицательных циклов нет (про них далее).

```py
# База
dp[0][*] = \infty
dp[0][s] = 0

# Переход
dp[k][v] = min{по всем e = (u, v)} dp[k - 1][u] + e.weight

# Ответ
dp[n - 1][v]
```

$\blacksquare$ **Асимптотика:**  
$O(mn)$

## Шпаргалка
|                   |              |
| ----------------- | ------------ |
| Веса $\in {1}$    | BFS          |
| Веса $\in [0, k]$ | 0-k BFS      |
| Веса $\ge 0$      | Дейкстра, A* |
| Веса $\in \R$     | Форд-Беллман |
---

## 41.
### Алгоритм Форда - Беллмана: нахождение кратчайших расстояний от одной вершины до всех в случае наличия отрицательных циклов.

$\blacksquare$ **Содержание:**

Как узнать что есть отрицательные циклы, то есть не для всех вершин ответ будет верным? Для решения посчитаем еще один слой $dp$ после последнего, а именно $dp[n][v]$. 

> &nbsp;  
> "Если существует отрицательный цикл, то найдется вершина $z$ (физически, она будет лежать на нем или достижима из него), что $dp[n][z] \lt dp[n - 1][z]$"  
> &nbsp;

$\triangle$  
Предположим, для всех вершин цикла $dp[n][z_i] \ge dp[n - 1][z_i]$.

Пусть $c_i = (z_i, z_{i + 1})$.
То есть $\forall i\ dp[n][z_{i + 1}] \le dp[n - 1][z_i] + |c_i|$ (т.к. по алгоритму берется минимум, больше стать не может). Тогда суммируем по всем вершинам цикла:

$$
\sum_{z_i \in Цикл} dp[n][z_i] \le \sum_{z_i \in Цикл} dp[n - 1][z_i] + \sum_{i} |c_i|
$$

Первая сумма $\ge$ Второй сумме, а Третья вообще отрицательная $\implies$ противоречие $\square$

Чтобы найти все вершины, для которых расстояние от начальной будет $-\infty$, нужно лишь запустить DFS из всех найденных прошлым действием вершин $z$. Все, что пройдет DFS (или BFS), будет иметь $dist(s, ...) = -\infty$

## 42.
### Алгоритм Флойда: поиск попарных расстояний в графе без отрицательных циклов.

$\blacksquare$ **Содержание:**
Используется для поиска кратчайшего расстояния между всеми парами вершин. Граф не должен иметь отрицательные циклы. Пусть $dp[i][j]$ - кратчайшая длина пути из $i$ в $j$. Используем $k$ - промежуточную вершину.

```py
# База
dp[i][j] = вес ребра (i, j), если оно существует, иначе \infty
dp[i][i] = 0

# Переход
for (k: [0, n)) {
  for (i: [0, n)) {
    for (j: [0, n)) {
      if (dp[i][k] != \infty and            # (i, k) существует   
          dp[k][j] != \infty and            # (k, j) существует
          dp[i][k] + dp[k][j] < dp[i][j])   # Новый путь через k короче прошлого
      {
        dp[i][j] = dp[i][k] + dp[k][j]
      }
    }
  }
}
```
**[ ! ]** Если после выполнения $dp[i][i] \lt 0$ для какой-то $i$, то из нее доступен отрицательный цикл.

$\blacksquare$ **Асимптотика:**  
$O(n^3)$

## 43.
### Остовный подграф, остовное дерево. Минимальный остов. Лемма о безопасном ребре.

$\blacksquare$ **Содержание:**

**| Остовный подграф** - подграф, содержащий все вершины.

**| Остовное дерево** - остовный подграф, являющийся деревом.

**| Минимальное остовное дерево (MST)** - остовное дерево с минимальной суммой весов ребер.

> &nbsp;  
> *(Лемма о безопасном ребре)* "Дан связный неориентированный взвешенный граф $(V, E)$. Пусть $S$ подмножество $E$ и существует MST $T$, содержащий все ребра из $S$, $C$ - одна из КСС в графе $(V, S)$, $e$ - самое дешевое ребро из ведущих из $C$ в другие КСС. Тогда найдется MST $T'$, что $S \cup \{e\} \subset E(T')$ "  
> &nbsp;

$\triangle$  
Пусть $e = (v, u)$, $v \in C$. $S \subset T$. Если $e \in S$, то доказывать нечего. Иначе: т.к. $T$ - дерево, $u$ и $v$ связаны, причем единственным путем. Рассмотрим этот путь. Найдем первое ребро $e'$, выходящее из $C$. Вес ребра $e \le e'$ (по условию). Тогда рассмотрим $T' = T \setminus {e'} + e$, $T'$ является MST (очев, просто в цикле одно ребро заменили на другое), так еще и вес уменьшился. $S \cup e \subset T'$. Получается, нашли другое MST, содержащее $e$ $\square$

**[ ! ]** Основываясь на этой лемме будут работать будущие алгоритмы: будет выбираться КСС, минимальное ребро по условию, MST будет расширяться за счет этого ребра.

## 44.
### Алгоритм Прима: доказательство корректности и реализации за $O(n^2),\ O(m \cdot \log n),\ O(m + n \log n)$.

$\blacksquare$ **Содержание:**

Заводим $S_0 = \varnothing \subset$ MST. Выберем вершину и самое дешевое ребро $e_1$ из нее исходящее, по лемме добавим его в $S_0$. Тогда $S_1 = S_0 \cup {e_1}$ тоже подмножество MST. Повторяем, пока не обойдем все вершины.

Алгоритм:

```py
d[*] = \infty

d[u] - минимальная стоимость ребра (v, u) между C и u. На каждом шаге в C добавляется u с минимальным значением d[u] (и по надобности фиксируем ребро (v, u) в итоговом MST). После этого, проходимся по все ребрам (u, w) и пытаемся обновить d[w] для них:

d[w] = min(d[w], cost(u, w))

Используя бинарную или фибоначчиеву кучи, можно улучшить асимптотику.
```

Корректность - очев скип.

$\blacksquare$ **Асимптотика:**  
$O(n^2)$ с линейным поиском минимума,  
$O(m \log n)$ с бинарной кучей,  
$O(m + n \log n)$ с фибоначчиевой кучей.

## 45.
### Система непересекающихся множеств (СНМ). Виды запросов. Эвристика по рангу, эвристика сжатия путей. Асимптотика ответа на запрос при использовании обеих эвристик `(б/д)`.

$\blacksquare$ **Содержание:**

**| СНМ** - Разбиение чисел $1 \dots n$ на непересекающиеся множества. Храним каждое множество в виде корневого дерева, для каждого элемента - его родителя. Для корня $p[v] = v$. Тогда, можно быстро проверять, в одном ли дереве лежат две вершины (дойти до корня и сравнить корни).

Методы этой структуры данных:

```py
# Получение корня
Get(v) {
  if (p[v] == v) {
    return v
  }
  return Get(p[v])
}

# Объединение двух множеств
Unite(u, v) {
  swap(u, Get(u))
  swap(v, Get(v))
  p[v] = u # С эвристикой меняем u и v местами, если v больше
}

# Проверка, лежат ли элементы в одном множестве
Same(u, v) {
  return Get(u) == Get(v)
}
```

**| Эвристика по рангу** - подвешивание меньшего дерева к большему.

**| Эвристика сжатия путей** - подвешивание вершин не по очереди, как бамбук, а все сразу к корню.

$\blacksquare$ **Асимптотика:**  
$O^*(1)$  
При использовании обеих эвристик. На самом деле, асимптотика равна $O(\alpha(n))$, где $\alpha(n)$ - обратная функция Аккермана, растущая очень медленно. Например, $\alpha(2^{2^{2^{16}}}) \lt 4$.

## 46.
### Асимптотика ответа на запрос в СНМ при использовании только эвристики по рангу.

> &nbsp;  
> "С эвристикой по рангу, все запросы - $O(\log n)$"  
> &nbsp;
 
$\triangle$  
Если дерево ранга $k$, то в нем как минимум $2^k = n$ вершин (по индукции, соединяя два дерева ранга $k - 1$, получаем ранг $k$. Подвешивая дерево меньшего размера к большему, получаем дерево размера $\ge$ 2 * размер меньшего). Поэтому, глубина дерева = ранг = $\log 2^k = \log n$ $\square$

## 47.
### Алгоритм Крускала: корректность, реализация, асимптотика.

$\blacksquare$ **Содержание:**

Сортируем все ребра в порядке возрастания, а затем по очереди добавляем по ребру в MST, если оно не добавляет циклов. Из двух предыдущих билетов, умеем работать с СНМ за $O(1)$, поэтому вся асимптотика состоит из асимптотики сортировки. 

$\blacksquare$ **Асимптотика:**  
$O(\text{<sorting>} + m)$  
($m$ на самом деле $m \cdot \alpha(n))$  
То есть асимптотика зависит от задачи: может даже за $O(m)$, если ребра уже отсортированы, или применима сортировка подсчетом.

## 48.
### Алгоритм Борувки: выбор минимального ребра из нескольких, корректность, реализация, асимптотика.

$\blacksquare$ **Содержание:**

Для каждой вершины определяем самое дешевое исходящее ребро. Все выбранные ребра добавляем в остов, сжимаем КСС (КСС превращается в единую вершину) и рекурсивно повторяем. Кратные ребра между КСС можно игнорировать, оставлять только одно, самое дешевое. Если из одной вершины исходит несколько ребер одного веса, то берем минимальный номер.

- Почему не появляются циклы?

При выборе ребра для каждой вершины, ориентируем его от этой вершины. Получится функциональный граф (тот, у которого из каждой вершины идет ровно 1 ребро). Все такие графы - циклы с торчащими деревьями. Каждое последующее ребро меньше предыдущего $\implies$ в цикле все ребра равны, иначе противоречие. Но мы выбираем ребра с минимальным номером, поэтому приходим к противоречию. Такое происходит для всех циклов, кроме циклов длины $\le$ 2. Но исходном графе ребер в себя и кратных нет $\implies$ циклов нет.

- Почему полученное остовное дерево минимально?

По индукции видим, что все ребра нашего MST, соединяющие КСС с остальным графом, минимальны из возможных. Все доказательство - многократное применение lemme о безопасном ребре.

$\blacksquare$ **Асимптотика:**  
$O(m \log n)$  
Т.к. первый проход линеен, а глубину рекурсии - логарифм (т.к. в худшем случае, количество вершин уменьшается в 2 раза).

## 49.
### Определение паросочетания в произвольном графе, двудольного графа, увеличивающего пути.

$\blacksquare$ **Содержание:**

**| Простой путь** - без повторения вершин и ребер.

**| Паросочетание** - подмножество ребер, любые два ребра из которого не имеют общих концов.

**| Двудольный граф** - для которого можно разбить множество вершин на 2 части, что любое ребро соединяет вершины из разных частей.

**| Насыщенная вершина / ребро** - является частью паросочетания.

**| Увеличивающий путь** (относительно парсоча) - путь, который:

- Простой
- Длина как минимум 1 ребро
- Начало и конец - ненасыщенные вершины
- Типы ребер (насыщ. / ненасыщ.) в нем чередуются

**[ ! ]** Чередование вдоль увелич. пути - добавляем все ребра не из парсоча (на этом пути) в парсоч, а те что были в парсоче - убираем. Получаем парсоч большего размера. В дальнейших алгоритмах будем искать увеличивающие пути пока возможно, и увеличивать за счет них парсоч.

## 50.
### Лемма об устройстве неориентированного графа, в котором степени всех вершин не превосходят двух.

$\blacksquare$ **Содержание:**

> &nbsp;  
> *(Лемма о неориентированном графе)* "Если $\Delta(H) \le 2$, то все его КСС - либо просто пути (без отростков), либо циклы"  
> &nbsp;

$\triangle$  
- Вершины степени 0 - отдельные КСС, все трививально.  
- Вершины степени 1 - или ведут в другую вершины степени 1 (тогда КСС - одно ребро), или ведут в вершину степени 2, которые ведут в итоге в вершину степени 1. Получили путь.  
- Вершины степени 2 - в итоге зацикливаются $\square$

## 51.
### Теорема Бержа.

$\blacksquare$ **Содержание:**

> &nbsp;  
> *(Теорема Бержа)* "Паросочетание M максимально $\Leftrightarrow$ относительно него нет увеличивающих путей"  
> &nbsp;

$\triangle$  
$\implies$ Просто выполняем чередование вдоль увличивающего пути и получаем более длинный парсоч, противоречие.  
$\Leftarrow$ Пусть увеличивающих путей нет, но $M'$ - максимальный парсоч, $|M'| \gt |M|$. Рассмотрим остовный подграф изначального графа, ребра берем только те, которые входят ровно в один из парсочей $M'$ и $M$ (симметрическая разность). В новом графе любая вершина имеет степень $\le 2$ (иначе у одного из парсочей ребра имеют общий конец). Далее, по лемме о неориентированном графе с вершинами степени не более 2 (см. предыдущий билет), знаем структуру нашего графа. Не может быть циклов нечетной длины (иначе опять два ребра имеют общую вершину). На четных циклах ребер из $M$ и $M'$ поровну, но $|M'| \gt |M|$ $\implies$ есть путь, на котором ребер $M'$ строго больше чем $M$. Покажем. что этот путь будет увеличивающим для $M$.

- Этот путь простой
- Длина $\ge$ 1
- Концевые вершины не могут быть насыщены, т.к. иначе путь можно продолжить
- Типы чередуются (т.к. была взята симметрическая разность)

Получается, это увеличивающий путь, но по предположению их нет $\implies$ противоречие $\square$

## 52.
### Алгоритм Куна. Корректность, реализация, асимптотика.

$\blacksquare$ **Содержание:**

Весь алгоритм: берем пустое множество, и пока в графе $G$ есть увеличивающий путь - выполняем вдоль него чередование, расширяя парсоч.

С этого момента считаем $G$ двудольным. За счет такого ограничения задача сильно упрощается. По определению двудольности делим вершины на 2 множества. Ориентируем ребра: те, что из парсоча - влево ($\leftarrow$), остальные - вправо ($\implies$). То есть увеличивающий путь - путь от ненасыщенной вершины в левой части до ненасыщенной вершины в правой части (ребра, соответственно, будут чередоваться).

Для удобства нумеруем вершины слева и справа начиная с нуля, в каждой из половин - независимая нумерация. В начале, ребер из парсоча очень мало, поэтому большинство ребер $\implies$. 

Просто запустим немного модифицированный DFS (называется Augment) из любой ненасыщенной вершины слева. 

```py
# Для каждой вершины слева храним список исходящих ребер
g[][]

# Для вершин справа - номер вершины слева, куда идет ребро (она единственна, так устроен парсоч)
match[]

# Для левых вершин храним булевский массив использования
used[]

# Введем метод, ищущий увеличивающий путь
Augment(v) -> bool {
  if (used[v]) {
    return False;
  }
  used[v] = True
  for (to: g[v]) {            # to уже находится в правой доле
    if (match[to] == -1 or    # 1. to ненасыщена, сразу берем ее
        Augment(match[to]))   # 2. to насыщена, ищем кто насытил ее
    {  
      match[to] = v
      return True
    }
  }
  return False
}
```

Весь алгоритм Куна:

```py
used[*] = False

for (v: [0, n)) {
  if (Augment(v)) {
    used[*] = False # Сбрасываем только если увеличили путь
  }
}
```

$\blacksquare$ **Асимптотика:**
$O(\text{answer} \cdot n)$, где $\text{answer}$ - размер максимального паросочетания.

## 53.
### Лемма об отсутствии увеличивающих путей из вершины при отсутствии таких путей относительного меньшего паросочетания.

$\blacksquare$ **Содержание:**

> &nbsp;  
> "Если $M'$ получено из $M$ чередованием вдоль увеличивающего пути, то если из некоторой $v$ нет увеличивающего пути для $M$, то его нет и для $M'$"  
> &nbsp;

$\triangle$  
Трудно, скип
$\square$

## 54.
### Определения независимого множества, вершинного покрытия. Связь определений.

$\blacksquare$ **Содержание:**

**| Независимое множество** - подмножество вершин графа, что никакие две вершины из него не соединены ребром.

**| Вершинное покрытие** - подмножество вершин графа, что любое ребро графа содержит хотя бы одну вершину из него.

$A \subset V$ - независимое множество $\Leftrightarrow$ $V \setminus A$ - вершинное покрытие

## 55.
### Алгоритм поиска максимального независимого множества и минимального вершинного покрытия в двудольном графе с помощью разбиения на доли $L^-, L^+, R^-, R^+$ (с доказательством). Теорема Кёнига.

$\blacksquare$ **Содержание:**

> &nbsp;  
> *(Теорема Кёнига)* "В двудольном графе размер вершинного покрытия равен размеру максимального паросочетания"  
> &nbsp;

Предъявим алгоритм:
1) Находим максимальное паросочетание.
2) Ориентируем ребра как в алгоритме Куна.
3) Запускаем обход (DFS или BFS) из всех ненасыщенных вершин левой доли.
4) Все вершины делим на 4 группы: посещененные / не посещенные и справа / слева ($L^-, L^+, R^-, R^+$).

Тогда, $L^+ \cup R^-$ - максимальное независимое множество, $L^- \cup R^+$ - минимальное вершинное покрытие.

$\triangle$    
Нет ребер из + в -, нет ребер из $R^-$ в $L^+$ (иначе как мы пришли из непосещенной в посещенную). Получается, $L^+ \cup R^-$ - независимое множество, т.к. ребер нет. Осталось доказать, что оно максимально. Докажем, что $L^- \cup R^+$ - минимальное. **< пропущено, очень трудно >** $\square$

$\blacksquare$ **Асимптотика:**  
$O(m\cdot \sqrt{n})$

## 56.
### Дефект паросочетания. Лемма Татта - Бержа.

$\blacksquare$ **Содержание:**

**| Дефект парсоча $(d(M))$** - количество ненасыщенных вершин относительно $M$.

> &nbsp;  
> *(Лемма Татта - Бержа)* $\forall$ парсоча $M$:
> $$ d(M) \ge \max_{R \subset V}\ (C_{odd}(G \setminus R) - |R|) $$  
> где $C_{odd}$ - количество КСС нечетного размера  
> &nbsp;

$\triangle$  
В графе с нечетным числом вершин нет парсоча с нулевым дефектом.

`! TODO`

$\square$

## 57.
### Алгоритм Эдмондса сжатия соцветий. Чередующееся дерево: определение и алгоритм построения.

$\blacksquare$ **Содержание:**

Этот алгоритм ищет максимальный парсоч в произвольном графе. Действует также, как Кун: начинает с пустого множества и добавляет увеличивающие пути пока возможно

**| Чередующееся дерево** - дерево, у которого корень ненасыщенный, вершины нечетной глубины - красные, четной - синие, ветвление может быть только в синих вершинах, ребра чередуются (из парсоча / не из парсоча).

`! TODO`

## 58.
### Алгоритм Эдмондса сжатия соцветий. Три случая в построении чередующегося дерева. Сжатие циклов (корректность - б/д). Асимптотика (оптимальная - б/д).

`! TODO`

## 59.
### Алгоритм Эдмондса сжатия соцветий. Корректность сжатия циклов.

`! TODO`

## 60.
### Определения сети, потока, величины потока, остаточной сети. Пример, почему нельзя обойтись без обратных рёбер.

$\blacksquare$ **Содержание:**

**| Сеть** - ориентированный взвешенный граф с двумя заданными вершинами. Вес ребер - их пропускная способность.

**| Поток** - $f: V \times V \implies \Z$
- $\forall$ $(u, v)$: $f(u, v) \le (u, v).cap$
- $f(u, v) = -f(v, u)$
- $\forall v \in V \setminus \{s, t\}$: $\sum_{u \in V} f(v, u) = 0$ (информация не задерживается в вершинах, сколько поступает, столько и вытекает.)

**| Величина потока** - $|f| = \sum_{v \in V} f(s, v)$ - сколько вытекает из начальной вершины $s$.

**| Остаточная сеть** - $G_f$ - максимальная пропускная способность всех ребер ($G$) минус нынешняя величина потока ($f$). Если у некоторых ребер остаточная $capacity = 0$, то их не добавляем (типа используется по полной).

> &nbsp;  
> "Поток максимален $\Leftrightarrow$ в $G_f$ нет пути из $s$ в $t$"  
> &nbsp;

После добавления потока к остаточной сети, обязательно нужно увеличить на ту же величину обратные ребра. Пример:

$\quad \quad \ \ \ \circ$  
$\quad \nearrow \ \ \ \quad\searrow$  
$s \quad \quad \uparrow \quad \quad t$  
$\quad \searrow \ \ \ \quad\nearrow$  
$\quad \quad \ \ \ \circ$  

Здесь $\max$ поток равен 2, но если пустить поток по центральному ребру, то больше 1 сделать нельзя. Но благодаря обратному ребру вниз, остаточная сеть будет иметь путь:

$\quad \quad \ \ \ \circ$  
$\quad \nearrow \ \ \ \quad$  
$s \quad \quad \downarrow \quad \quad t$  
$\quad \quad \ \ \ \quad\nearrow$  
$\quad \quad \ \ \ \circ$  

По формуле: $cap - f = 0 - (-1) = 1$ - есть путь

## 61.
### Определения разреза, величины разреза, величины потока через разрез. Лемма о равенстве величины потока и величины потока через разрез.

$\blacksquare$ **Содержание:**

**| Разрез** - пара $(S, T)$,  $s \in S$, $v \in V$,  $S \sqcup T = G(V)$. Т.е. разбиение всех вершин на 2 множества.

**| Величина разреза** -
$$c(S, T) = \sum_{\begin{array}{c}
  \text{$u \in S$} \\
  \text{$v \in T$}
\end{array}} (u, v).cap$$

**| Величина потока через разрез** - 
$$f(S, T) = \sum_{\begin{array}{c}
  \text{$u \in S$} \\
  \text{$v \in T$}
\end{array}} f(u, v)$$

> &nbsp;  
> *(Лемма)* "Если $(S, T)$ - разрез, а $f$ - поток, то $f(S, T) = |f|$"  
> &nbsp;

$\triangle$  
$f(S, T) = f(S, V) - f(S, S) = f(S, V)$ (т.к. по антисимметричности, $f(S, S) = 0$) $\implies$ $f(S, T) = f(S, V) = f(\{s\}, V) + f(S \setminus \{s\}, V) = |f| + f(S \setminus \{s\}, V) = |f|$ (т.к. сумма входящих и исходящих равна нуля для всех вершин кроме $s$ и $v$, а $S \setminus \{s\}$ не содержит ни олну из них) $\square$

## 62.
### Теорема Форда - Фалкерсона.

$\blacksquare$ **Содержание:**

> &nbsp;  
> *(Теорема Форда - Фалкерсона)* "Следующие условия эквивалентны:"
> 1) $|f| = \max$
> 2) в $G_f$ нет пути из $s$ в $t$.
> 3) $\exists (S, T)$: $c(S, T) = |f|$  
> &nbsp;

$\triangle$  
$1 \implies 2$:  
Очев, если бы путь был, по нему можно было бы пустить поток и $\max$ поток бы увеличился.  
$2 \implies 3$:  
Определим $S$ - все вершины, достижимые из $s$ в остаточной сети, $T$ - остальные. $s \in S$ (путь в себя есть), $t \notin S \implies t \in T$ (т.к. по предположению, пути нет). Ребер из $S$ в $T$ нет (иначе в $T$ были бы достижимые) $\implies$ $c(S, T) = \sum_{u \in S,\ v \in T} (u, v).cap$ = $\sum_{u \in S,\ v \in T} f(u, v)$ = $|f|$  
$3 \implies 1$:  
Все потоки меньше всех разрезов, но есть один поток, равный разрезу. То есть это $\min$ разрез и $\max$ поток.

## 63.
### Алгоритм Форда - Фалкерсона. Корректность, асимптотика. Пример сверхполиномиального (от размера входа) времени работы.

$\blacksquare$ **Содержание:**

Находим путь в остаточной сети (например DFS-ом), пускаем по нему максимально возможный поток, повторяем. Корректность следует из теоремы.

Но есть примеры, на которых он работает сверхполиномиально. Например:  

$\quad \quad \ \ \ \circ$  
$\quad \nearrow \ \ \ \quad\searrow$  
$s \quad \quad \uparrow \quad \quad t$  
$\quad \searrow \ \ \ \quad\nearrow$  
$\quad \quad \ \ \ \circ$

Здесь все ребра весят очень много, кроме центрального - оно очень мало. Тогда, очевидно, нужно пустить один поток по верху и один по низу, а среднее ребро не использовать. Но наш алгоритм будет очень много раз переворачивать среднее ребро туда-сюда. Чтобы решить эту проблему, можно из всех путей выбирать тот, у которого минимальное количество ребер. Это называется алгоритм Эдмондса-Карпа.

$\blacksquare$ **Асимптотика:**  
$O(F \cdot n)$, где $F$ - величина $\max$ потока.

## 64.
### Алгоритм Эдмондса - Карпа. Корректность.

$\blacksquare$ **Содержание:**

Все то же самое, только меняем DFS на BFS. Так будет всегда находиться кратчайший по количеству ребер путь. Корректность следует из прошлого алгоритма.

$\blacksquare$ **Асимптотика:**  
$O(nm^2)$

## 65.
### Лемма о возрастании dist(s, v) между последовательными итерациями алгоритма Эдмондса - Карпа.

$\blacksquare$ **Содержание:**

> &nbsp;  
> "Пусть $G_f$ и $G_{f'}$ - два последовательных состояния остаточной сети, $d(v) = dist(s, v)$ в $G_f$, $d'(v)$ - в $G_{f'}$ соответственно. Тогда $\forall v$ $d'(v) \ge d(v)$"  
> &nbsp;

$\triangle$  
От противного: из всех вершин $v$, для которых $d'(v) \lt d(v)$ выберем с минимальным $d'(v)$. Рассмотрим кратчайший путь $dist(s, v)$, в нем вершину $u$, что $(u, v)$ - последнее ребро в пути. Тогда $d'(u) + 1 = d'(v)$. Тогда $d'(u) \ge d(u)$, т.к. $v$ выбиралась минимальной среди вершин с таким свойством. Ребро $(u, v)$ могло или взяться из $G_f$, или появиться в $G_{f'}$ впервые.  

- В первом случае: $d(v) \le d(u) + 1 \le d'(u) + 1 = d'(v)$ - противоречие с предположением $d'(v) \lt d(v)$.  

- Во втором случае: $(u, v)$ не было в $g_{f'}$. Это значит, что пустился поток вдоль обратного ребра $(v, u)$. Это значит, что $d(v) = d(u) - 1 \le d'(u) - 1 \le d'(v) - 2$, но по предположению $d'(v) \lt d(v)$  

$\implies$ $\forall v$ $d'(v) \ge d(v)$ $\square$

## 66.
### Лемма о числе насыщений ребра в алгоритме Эдмондса - Карпа. Асимптотика этого алгоритма.

$\blacksquare$ **Содержание:**

> &nbsp;  
> *(Лемма)* "Каждое ребро в алгоритме Эдмондса - Карпа насыщается (после очередной операции становится $c = f$) не более $O(n)$ раз"  
> &nbsp;

$\triangle$  
трудно, скип $\square$

## 67.
### Алгоритм Форда - Фалкерсона с масштабированием, асимптотика.

$\blacksquare$ **Содержание:**

Нужен, когда пропускная способность ребер может сильно отличаться, например в миллионы раз. Идея: пускаем первый поток. Среди всех ребер берем максимальное по пропускной способности ($\Delta$). Берем максимальное $k \in \N$, что $\Delta \ge 2^k$. Итерируемся от $k$ до $0$: Все ребра целочисленно делим на $k$ (многие могут стать нулем), по полученному графу пускаем потов величины 1 пока возможно. Все что смогли пустить - умножаем на $2^k$ и считаем остаточную сеть. Для нее повторяем процедуру для $2^{k-1}$ и т.д.

$\blacksquare$ **Асимптотика:**  
$O(m^2 \cdot \log(\Delta))$

## 68.
### Определение слоистой сети, блокирующего потока. Алгоритм Диница, доказательство корректности.

$\blacksquare$ **Содержание:**

**| Слоистая сеть** - Разбиваем BFS-ом сеть на кластеры по расстоянию (мн-во вершин на расстоянии 0 ($V_0 = \{s\}$), на расстоянии 1 ($V_1$), ... , $V_l = \{t\}$). Оставляем только ребра из $V_i$ в $V_{i + 1}$ (ровно на 1 увеличение, по другому не бывает), все ребра внутри кластеров и ведущие в меньшие $V$ удаляем.

**| Блокирующий поток** - поток, который нельзя увеличить без введения обратных ребер.

Идея алгоритма Диницы - насытить сразу все кратчайшие пути. Пока в $G_f$ есть путь из $s$ в $t$, строим слоистую сеть и в ней пускаем какой нибудь блокирующий поток. Корректность следует из теоремы Форда-Фалкерсона.

$\blacksquare$ **Асимптотика:**  
$O(nm^2)$

## 69.
### Реализация алгоритма Диница. Асимптотика.

$\blacksquare$ **Содержание:**

Строить слоистую сеть легко - один BFS и дальше просто проверяем, что для всех используемых $(u, v):$  $d[u] + 1 = d[v]$.  
Как искать блокирующий поток? Пусть на каждой итерации, если по ребру нельзя пустить поток, то оно неинтересно и не рассматриваем его дальше. Поддерживаем указатель на номер первого интересного ребра - $ptr[v]$. Вспомогательный метод для поиска блокирующего потока принимает нынешнюю вершину и набранный поток из пройденных:

```py
DFS(v, f) {
  if (v == t) {
    return f; # Дошли до конца, возвращаем собранный поток
  }
  while (ptr[v] != g[v].size()) {
    if (e.cap == e.flow ||          # Уже заполнено
        dist[e.to] != dist[v] + 1)  # Не из слоистой сети
    {
      ++ptr[v] # Помечаем бесполезным
      continue # Переходим к следующему исходящему ребру
    }
    x = DFS(e.to, min(f, e.cap - e.flow))
    if (x == 0) {
      ++ptr[v] # Не смогли протолкнуть, помечаем бесполезным
      continue
    }
    # Нашли путь, по которому можно пустить x
    e.flow += x
    e_rev.flow -= x # Не забываем пустить по обратному противоположный
    return x
  }
  return 0
}
```

Весь алгоритм Диница:

```py
Dinits() {
  max_flow = 0
  while (True) {
    BFS() # Строим слоистую сеть
    if (нет пути между s и t) {
      break
    }
    ptr.reset() # Сбрасываем только после полной перестройки графа для очередной итерации 
    while(True) {
      x = DFS(s, \infty) # Пытаемся протолкнуть хоть что-то
      if (x == 0) {
        break # Ничего не протолкнулось
      }
      max_flow += x
    }
  }
}
```

$\blacksquare$ **Асимптотика:**  
$O(n^2 m)$

## 70.
### Первая теорема Карзанова о числе итераций алгоритма Диница.

$\blacksquare$ **Содержание:**

| $C_{in} = \sum_{u} (u, v).cap$  
| $C_{out} = \sum_{w} (v, w).cap$

**| Потенциал вершины** - $p(v) = \min(C_{in}(v), C_{out}(v))$

**| Потенциал сети** - $P = \sum_{v \in V \setminus \{s, t\}} \ p(v)$

**Первая вспомогательная лемма:**

> &nbsp;  
> "$l = dist(s, t)$. $F$ - максимальный поток. $P$ - потенциал сети. Тогда $l \le 1 + \frac{P}{F}$ "  
> &nbsp;

$\triangle$  
Разбиваем вершины на слои, <u>но не удаляем никакие ребра</u> как в Динице! Пусть $P_i$ - суммарны потенциал вершин в слое $V_i$. Тогда $F \le P_i$ (очев, иначе $F$ просто не пройдет через $V_i$). Сложим для всех слоев крое последнего:  

$$ (l - 1) \cdot F \le \sum_{i = 1}^{l - 1} P_i \le P $$

Поделили, перенесли единичку, готово $\square$

**Вторая вспомогательная лемма:**

> &nbsp;  
> "$P(G) = P(G_f)$"   
> &nbsp;

$\triangle$  
Рассмотрим вершину $v$. При переходе к остаточной сети, поток $f$ проходит через вершину, к входящему ребру прибавляется $+ f$, к исходящему $- f$. То есть $C_{in}$ и $C_{out}$ не меняются $\implies$ потеницал всей сети не меняется $\square$

> &nbsp;  
> *(Первая теорема Карзанова)* "Число итераций в алгоритме Диница - $O(\sqrt{P})$ "  
> &nbsp;

$\triangle$  
Пусть $F$ - сколько потоко осталось пустить. $l = dist(s, v)$ в $G_f$. По 2 лемме, потенциал $P$ не меняется. По 1 лемме, $\sqrt{P} \le l \le 1 + \frac{P}{F}$ (т.к. сделали $\sqrt{P}$ итераций, на каждом шаге $dist$ увеличивается хотя бы на 1) $\implies$ $F \le \frac{P}{\sqrt{P} - 1} = O(\sqrt{P})$. То есть после $\sqrt{P}$ итераций остается пустить $O(\sqrt{P})$ потока ($O(\sqrt{P})$ итераций). Всего:
$\sqrt{P} + O(\sqrt{P}) = O(\sqrt{P})$ $\square$

## 71.
### Быстродействие алгоритма Диница в единичных сетях.

$\blacksquare$ **Содержание:**

**| Единичная сеть** - в которой пропускные способности рёбер принимают только значения 0 и 1.

> &nbsp;  
> В единичной сети $P \le O(m)$  
> &nbsp;

$\triangle$  
Так как сеть единичная, то $C_{in}(v) = indeg(v)$, $C_{out}(v) = outdeg(v)$. $p(v) = \min(indeg(v), outdeg(v)) \le indeg(v) + outdeg(v)$.  
Следовательно:

$$
P\ = \sum_{v \in V \setminus \{s,t\}} p(v) \le \sum_{v \in V} indeg(v) + \sum_{v \in V} outdeg(v) = 2m = O(m)
$$

$\square$

> &nbsp;  
> "В единичной сети одна итерация алгоритма Диница работает за $O(m)$ вместо $O(nm)$"  
> &nbsp;

Так как за всё время DFS-ом каждое ребро рассматривается максимум 1 раз (либо проталкиваем по нему поток, либо исключаем из рассмотрения).

**Из этих двух утверждений и теоремы Карзанова:**
- количество итераций $k = O(\sqrt{P})$
- $P = O(m) \implies \sqrt{P} = O(\sqrt{m}) \implies k = O(\sqrt{m})$
- Асимптотика одной фазы - $O(m)$

$\blacksquare$ **Асимптотика:**  
$O(m\sqrt{m})$

## 72.
### Алгоритм Хопкрофта - Карпа поиска максимального паросочетания в двудольном графе. Корректность и асимптотика.

$\blacksquare$ **Содержание:**

Поиск $\max$ парсоча в двудольном графе можно свести к поиску $\max$ потока. Для этого вводим фиктивные вершины $s$ и $t$. Из $s$ проводим ребра во все вершины левой доли с $cap = 1$, из всех вершин правой доли проводим ребра в $t$. Тогда потенциал всей сети $P = n$. Т.к. сеть единичная, каждая итерация работает за $O(m)$. По теореме Карзанова, итераций всего $O(\sqrt{P}) = O(n)$.

$\blacksquare$ **Асимптотика:**  
$O(m\sqrt{n})$

## 73.
### Алгоритм Штор - Вагнера поиска минимального глобального разреза.

$\blacksquare$ **Содержание:**

**| Глобальный минимальный разрез** - разрез минимальной величины, но без фиксации $s$ и $t$. Т.е. по абсолютно всем разбиениям $S \sqcup T = V$.

Две вершины либо по разные доли в искомом разрезе, либо в одной доле.

Алгоритм Штор-Вагнера ищет глобальный минимальный разрез. Основывается он на том, что в искомом разбиении две вершины лежат либо по разные доли в искомом разрезе, либо в одной доле.

- Находим (с помощью алгоритма ниже) вершины $s$ и $t$, кандидаты на минимальный разрез.  

Алгоритм поиска кандидатов на глобальный минимальный разрез:  
Обозначение: $A_i = \{a_1, \dots , a_i\}$. Берем вершину в графе: $a_1$ - любая. Далее:  
$$
a_i = \argmax_{v \in V \setminus A_{i - 1}}\ C_i, \ где \ \ C_i = \sum_{w \in A_{i - 1}} (v, w).cap 
$$  
Тогда, если рассмотреть $a_{n - 1}$ и $a_n$, то они годятся на роли $s$ и $t$ соответственно. Минимальный разрез между ними будет $MinCut(s, t) = C_n$.

- $res = \min(res, MinCut(s, t))$.
- Склеиваем две вершины в одну (ребра, ведущие в одну вершину склеиваем, между $s$ и $t$ удаляем).
- Запускаем заново на графе, в котором стало на одну вершину меньше.

$\blacksquare$ **Асимптотика:**  
$O(n^3)$ с простым перебором. Лучше, когда ребер много ($m = \Theta(n^2)$)  
$O(nm \log n + n^2)$ с бинарной кучей. Лучше, если ребер мало

## 74.
### Min cost flow: постановка задачи. Критерий минимальности стоимости потока величины k. Алгоритм поиска потока величины k минимальной стоимости. Асимптотика.

$\blacksquare$ **Содержание:**

Теперь, кроме $capacity$, у каждого пебра будет еще и цена за единицу потока. Этакая аренда кабеля. Задача - найти поток величины $k$ с минимальной стоимостью. Про обратные ребра:  
если $\hspace{7em}(cap, cost) \implies$  
то обратное $\hspace{3em}\leftarrow (0, -cost)$

**| Стоимость потока** - $cost(f) = \frac{1}{2} \sum_{e} f(e) \cdot cost(e)$.

> &nbsp;  
> *(Критерий минимальности потока)* " Пусть $|f| = k$. Он имеет $\min$ стоимость среди потоков величины $k$ $\Leftrightarrow$ в $G_f$ нет циклов отрицательной стоимости"  
> &nbsp;

$\triangle$  
$\implies$ Очев, иначе можно пустить по нему поток и уменьшить стоимость  
$\Leftarrow$ Пусть $cost(f) \gt cost(f^*)$. Введем $g(e) = f^*(e) - f(e)$. Тогда, $g$ - поток величины ноль в $G_f$. Докажем по определению:  
- Ограниченность сверху $capacity$ ребра:  
$g(e) \le e.cap - f(e) = cap_{G_f}(e)$.

- Антисимметричность:  
$g(u, v) = f^*(u, v) - f(u, v) = -f^*(v, u) + f(v, u) = -g(v, u)$.

- Равенство входящего и исходящего потоков в каждой вершине кроме $s$ и $t$:  
$\sum_{u} g(v, u) = 0$ - верно, т.к. верно для $f^*(e)$ и $f(e)$.

Итак, $g$ - поток в $G_f$. Его величина - ноль, а стоимость отрицательна (по определению) $\implies$ это цикл в $G_f$ $\square$

Алгоритм поиска простой: находим минимальный по стоимости поток размера 1, пускаем его, повторяем то же самое с остаточной сетью еще $k - 1$ раз. Это корректно, если нет отрицательных циклов.  

$\blacksquare$ **Асимптотика:**  
$O(knm)$  
($O(nm)$ - Форд-Беллман)

## 75.
### Потенциалы Джонсона. Поиск min cost k-flow с помощью алгоритма Дейкстры.

$\blacksquare$ **Содержание:**

Пусть $\varphi: V \implies \Z$. Тогда создадим модифицированную версию $cost$:  
$cost_{\varphi}(u, v) = cost(u, v) + \varphi(u) - \varphi(v)$.  
Теперь $cost_{\varphi}(пути) = cost(пути) + \varphi(s) - \varphi(t)$ (типа телескопическая сумма). Все пути поменялись на константу $\implies$ найти минимальный путь по $cost(u, v)$ равносильно найти минимальный путь по $cost_{\varphi}(u, v)$. Если все $cost_{\varphi}(v) \ge 0$, то мы сможем пускать Дейкстру вместо Форда-Беллмана (она быстрее). Для этого один раз пустим Форда-Беллмана, и положим $\varphi(v) = dist(s, v)$. Тогда $\forall (u, v)$:  
$cost_{\varphi}(u, v) = cost(u, v) + dist(s, u) - dist(s, v) \ge 0$ (по неравенству треугольника).

Дальше пускаем Дейкстру и все как в 

$\blacksquare$ **Асимптотика:**  
$O(mn + km \log n)$  
($O(m \log n)$ - Дейкстра, иногда выгодно писать за $O(n^2)$)

## 76.
### Определение центроида в дереве. Алгоритм поиска центроида в дереве. Лемма о количестве центроидов.

**| Центроид** - вершина, после удаления которой граф распадается на КСС размера не более $\frac{n}{2}$.

> *(Лемма о количестве центроидов)* "В любом дереве есть хотя бы один центроид, и их 1 или 2, и они соединены ребром"

$\triangle$  
- Докажем, что центроид всегда существует, предъявив алгоритм поиска.  
Подвесим дерево за какую нибудь вершину. $s[v]$ - количество вершин в поддереве, включая $v$. $s[root] = n$. Спускаемся в ребенка, если его поддерево размера $\ge \frac{n}{2}$. Тогда в итоге дойдем до вершины $u$, что $s[u] \ge \frac{n}{2}$, а $\forall c_u$ - ребенок $u$: $s[c_u] \lt \frac{n}{2}$. Тогда размер всего остального графа без поддерева $u$ тоже строго меньше $\frac{n}{2}$ $\implies$ $u$ - центроид.  
- Докажем, что их не больше 2.  
Пусть их $\ge 2$. Выберем два произвольных. Предположим ребра между ними нет, есть некоторый путь по ребрам. Дальше легко заметить, что множества оставшихся КСС после удаления одного из них пересекаются, получаем противоречие, что вершин в графе $\le \frac{n}{2} + \frac{n}{2} -$ пересечение $\lt n$. Значит, любые два центроида соединены ребром. Значит, если бы их было 3 (или более), то они должны находиться в виде треугольника, а значит образовывать цикл. Противоречие $\square$

## 77.
### Определение изоморфизма графов. Алгоритм проверки изоморфности двух ориентированных или неориентированных деревьев за $O(n \log n)$.

**| Изоморфизм графов** - 

- $\varphi: V(G_1) \implies V(G_2)$ - биекция
- $(u, v) \in E(G_1) \Leftrightarrow ((\varphi(u), \varphi(v)) \in E(G_2))$

Алгоритм поиска изоморфизма в корневых деревьях: Корень переходит в корень. Введем отношение эквивалентности: $c(u) = c(v)$ $\Leftrightarrow$ поддеревья $u$ и $v$ изоморфны. Классы вершин определяются мультимножеством классов эквивалентности детей (например, $\{1, 1, 3, 2\}$).

```py
# Заводим хэш таблицу
std::map<std::vector<int>, int> num

# И счетчик классов эквивалентности
k = 0

DFS(v) {
  a = []
  for (to: g[v]) {
    DFS(v)
    a.push_back(c[to])
  }
  a.sort()
  if (num[a] == NULL) {
    num[a] = k++
    c[v] = num[a]
  }
}
```

Оценим асимптотику. Она складывается из асимптотики сортировки и обращения к КЧД:
$$
\sum_{v \in Дерево} |a| \log |a| + \sum_{v \in Дерево} |a| \log n \le \sum_{v \in Дерево} 2 \cdot |a| \log n \le 2n \log n = O(n \log n)
$$
На некорневых деревьев алгоритм тот же, только вместо корня берем центроиды (Их не более чем 2, поэтому надо будет рассмотреть не более 4 пар, найти хотя бы в одной изоморфизм).

$\blacksquare$ **Асимптотика:**  
$O(n \log n)$

## 78.
### Задача LCA. Постановка, решение с помощью двоичных подъёмов.

$\blacksquare$ **Содержание:**

**| Корневое дерево** - ориентированное дерево, в котором в каждую вершину (кроме корня) входит ровно 1 ребро. $m = n - 1$.

**| LCA (lowest commom ancestor)** - наименьший (т.е. максимальная глубина) общий предок двух вершин.

> &nbsp;  
> *(Критерией предка)* $u$ предок $v$ $\Leftrightarrow$
$\begin{cases}
tin[u] \le tin[v] \\
tout[u] \ge tout[v]
\end{cases}$  
> &nbsp;

Пусть $shifts[k][v]$ - предок $v$ в $2^k$ - ом поколении. $shifts[0][v] = parent(v)$ (если $v$ корень - то родитель сам себе. $shifts[k + 1][v] = shifts[k][shifts[k][v]]$. На этот подсчет уйдет $O(n \log n)$.

```py
LCA(u, v) {
  if (ISAncestor(u, v)) {
    return u
  }
  for (k: [logn, 0)) {
    if (not IsAncestor(shifts[k][u], v)) {
      u = shifts[k][u]
    }
  }
  return parent[u]
}
```

$\blacksquare$ **Асимптотика:**  
$O(n \log n)$

## 79.
### Задача LCA. Решение с помощью эйлерова обхода.

$\blacksquare$ **Содержание:**

Проходимся по всему графу, сохраняя номер и глубину каждой вершины. Сохраняем при любом входе в вершину, даже повторном. Тогда, чтобы найти LCA, нужно найти вершину с минимальной глубиной на подмассиве. Делать это можно за $O(1)$ с предпосчетом за $O(n \log n)$ с помощью Sparse table.

$\blacksquare$ **Асимптотика:**  
$O(1)$

## 80.
### Задача LCA. Алгоритм Фарах-Колтона и Бендера.

$\blacksquare$ **Содержание:**

- **Предпосчет:**  
Строим массив глубин, как и в прошлом алгоритме. Заметим, что лубина соседних элементов отличается на $\plusmn 1$. Дробим массив на части размера ровно $k = \frac{\log_{2} n}{2}$ (если последний блок маленький, дополним мусором). Каждую часть можно закодировать парой $(k, mask)$, где $k$ - глубина первого элемента в блоке, а $mask$ кодирует увеличение или уменьшение глубины (1 - поднялись вверх, уменьшение глубины, 0 - спустились вниз, увеличение). Всего масок - $2^{k - 1} \le 2^{\frac{\log_{2} n}{2}} = \sqrt{n}$. Для всех масок предпосчитаем минимумы на всех подотрезках. $dp[mask][l][r]$ - минимум на отрезке $[l, r]$. Время на предпосчет - $\sqrt{n}$ масок, для каждой $O(\log^2 n)$ подотрезков. Всего $O(\sqrt{n} \log^2 n)$. В искомый подотрезок входит несколько блоков целиком, и не более 2 частично. Всего блоков $\frac{n}{k}$. Строим Sparse table на минимумах блоков. Это делается за $O(\frac{n}{k} \log \frac{n}{k})$. Всего: $\frac{n}{k} \log \frac{n}{k} \le \frac{n}{k} \log n = \frac{2n}{\log n} \log n = 2n = O(n)$.

- **Ответ на запрос:** Для ответа нужен минимум между цельными блоками, левым блоком и правым блоком. Первый получаем из Sparse table, осальные предпосчитаны масками.

$\blacksquare$ **Асимптотика:**  
$O(1)$

## 81.
### Решение статической задачи RMQ (range minimum query) с предподсчётом за $O(n)$ и ответом на запрос за $O(1)$.

$\blacksquare$ **Содержание:**

Сведем RMQ к LCA. Строим декартово дерево за $O(n)$ на парах $(i, a_i)$. Приоритеты не случайны, поэтому глубина может быть большой, но это не важно. Минимумом будет LCA концов промежутка.

## 82.
### Heavy - light декомпозиция. Обновление значений и сумма на путях.

$\blacksquare$ **Содержание:**

Суть метода heavy-light декомпозиции (HLD) - построение похожей структуры как дерево отрезков на массиве, только на графе-дереве.  
Дано дерево, в вершинах записаны числа. Нужно обрабатывать запросы суммы на пути и увеличения числа в вершине $v$ на $\Delta$. Подвесим дерево за какую то вершину, обозначим $s[v]$ - количество вершин в поддереве, включая $v$. Разобьем все ребра на 2 группы - тяжелые и легкие. Рассматривая вершину, помечаем тяжелым то ребро, которое ведет в ребенка с наибольшим $s[v]$. Остальные легкие. На каждом тяжелом пути (несколько подряд идущих тяжелых ребер) строим ДО (по вершинам на пути). На любом простом пути не более $O(\log n)$ легких ребер (вверх логарифм и вниз логарифм).

- Сумма на пути от $u$ до $v$:  
Ищем LCA, прыгаем через одно легкое ребро по путям из тяжелых ребер. $2 \log n$ запросов к ДО, каждый запрос за $O(\log n)$. Итого: $O(\log^2 n)$.

- Смена значения в вершине:  
Просто изменить значение в одном из ДО, к которому принадлежит данная вершина. Итого: $O(\log n)$.

## 83.
### Центроидная декомпозиция. Поиск числа пар вершин в дереве на расстоянии d.

$\blacksquare$ **Содержание:**

Суть метода центроидной декомпозиции:  
Пусть дано дерево, нужно посчитать в нем количество каких то обьектов. Возьмем какой нибудь центроид в дереве, подвесим дерево за него. Посчитаем количество обьектов, которые пропадут, если удалить центроид, и прибавим к ответу. Удалим центроид и рекурсивно запустимся от поддеревьев.  
$T(n) = O(n) + \sum_{i}^{k} T(s_i)$, $s_i \le \frac{n}{2}$, $\sum_{i}^{k} s_i = n - 1$.  
Тогда, решение такой реккуренты находится за $O(n \log n)$. Потому что глубина логарифмическая, подсчет каждой глубины за линию.

`! TODO`

---
